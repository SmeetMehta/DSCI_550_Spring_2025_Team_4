{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PKWnUgOkw9mc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean word cloud data has been generated：wordcloud.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Read JSON\n",
        "with open(\"haunted_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Extract all description fields and merge them into one large text\n",
        "text = \" \".join(item.get(\"description\", \"\") for item in data)\n",
        "\n",
        "# Clean up the text: remove punctuation, lower caseization\n",
        "text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text).lower()\n",
        "\n",
        "# Split into words\n",
        "words = text.split()\n",
        "\n",
        "# Set up stop words\n",
        "stopwords = set(\"\"\"\n",
        "a about above after again against all also am an and any are arent as at be because been before being below between\n",
        "both but by can cant cannot could couldnt did didnt do does doesnt doing dont down during each even few for from further get\n",
        "had hadnt has hasnt have havent having he hed hell hes her here heres hers herself him himself his how hows i id\n",
        "ill im ive if in into is isnt it its itself lets like me more most mustnt my myself no nor not now of off on once one only or\n",
        "other ought our ours ourselves out over own same shant she shed shell shes should shouldnt so some still such than that\n",
        "thats the their theirs them themselves then there theres these they theyd theyll theyre theyve this those through\n",
        "to too under until up very was wasnt we wed well were weve what whats when whens where wheres which while who whos\n",
        "whom why whys will with wont would wouldnt you youd youll youre youve your yours yourself yourselves\n",
        "\"\"\".split())\n",
        "\n",
        "# Filtering: remove stop words + too short words\n",
        "filtered_words = [word for word in words if word not in stopwords and len(word) > 2]\n",
        "\n",
        "# Count word frequency\n",
        "counter = Counter(filtered_words)\n",
        "\n",
        "# Top 100 high-frequency words\n",
        "top_words = counter.most_common(100)\n",
        "\n",
        "# Convert to D3 word cloud format\n",
        "wordcloud_data = [{\"text\": word, \"size\": freq * 2} for word, freq in top_words]\n",
        "\n",
        "# Write JSON file\n",
        "with open(\"wordcloud_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(wordcloud_data, f, indent=2)\n",
        "\n",
        "print(\"Clean word cloud data has been generated：wordcloud.json\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
